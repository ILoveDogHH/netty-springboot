server:
  port: 8888
  #servlet:
  #  context-path: /l2cache-example
netty:
  server:
    port: 11211

logging:
  level:
    root: info
    # 日志级别指定到包或类
    com.github.jesse.l2cache: debug

spring:
  application:
    name: l2cache-example

# 二级缓存配置
# 注：caffeine 不适用于数据量大，并且缓存命中率极低的业务场景，如用户维度的缓存。请慎重选择。
l2cache:
  config:
    # 缓存实例Id，唯一标识应分布式场景下的一个缓存实例节点
    #instanceId: a1
    # 是否存储空值，默认true，防止缓存穿透
    allowNullValues: true
    # 空值过期时间，单位秒
    nullValueExpireTimeSeconds: 30
    # 缓存类型
    cacheType: redis
    # 组合缓存配置
    composite:
      # 一级缓存类型
      l1CacheType: caffeine
      # 二级缓存类型
      l2CacheType: redis
      # 是否全部启用一级缓存，默认false
      l1AllOpen: false
      # 是否手动启用一级缓存，默认false
      l1Manual: false
      # 手动配置走一级缓存的缓存key集合，针对单个key维度
      l1ManualKeySet:
        - a
        - actLimitMarkupCache:11_2
        - userCache:user01
        - userCache:user02
        - userCache:user03
        - userCache:user04
        - "[actLimitMarkupCache:11_3]"
      # 手动配置走一级缓存的缓存名字集合，针对cacheName维度
      l1ManualCacheNameSet:
        - compositeCache
        - goodsSpecCache
        - goodsPriceRevisionCache
        - brandCache
    # 一级缓存
    caffeine:
      # 是否自动刷新过期缓存 true 是 false 否
      autoRefreshExpireCache: false
      # 缓存刷新调度线程池的大小
      refreshPoolSize: 2
      # 缓存刷新的频率(秒)
      refreshPeriod: 10
      # 高并发场景下建议使用refreshAfterWrite，在缓存过期后不会被回收，再次访问时会去刷新缓存，在新值没有加载完毕前，其他的线程访问始终返回旧值
      # Caffeine在缓存过期时默认只有一个线程去加载数据，配置了refreshAfterWrite后当大量请求过来时，可以确保其他用户快速获取响应。
      # 创建缓存的默认配置（完全与SpringCache中的Caffeine实现的配置一致）
      # 如果expireAfterWrite和expireAfterAccess同时存在，以expireAfterWrite为准。
      # 推荐用法：refreshAfterWrite 和 @Cacheable(sync=true)
      # 注意：当缓存项在有效期内重复利用率很低时，不适合用本地缓存，如3千万用户参加抢购活动，用户信息的缓存，则不能用本地缓存。
      # 因为超过最大数量限制时，再往里面添加元素，会异步按照LFU淘汰元素，若未及时淘汰，在大量用户请求的情况，会导致堆内存飙升，频繁的FullGC和YoungGC，最终导致OOM。
      defaultSpec: initialCapacity=10,maximumSize=2,refreshAfterWrite=2m,softValues,recordStats
      # 设置指定缓存名的创建缓存配置(如：userCache为缓存名称)
      specs:
        #userCache: initialCapacity=10,maximumSize=2,expireAfterWrite=2m
        userCache: initialCapacity=10,maximumSize=200,refreshAfterWrite=2m,recordStats
        userCacheSync: initialCapacity=10,maximumSize=200,refreshAfterWrite=2m,recordStats
        # 无过期时间配置
        queryUserSync: initialCapacity=10,maximumSize=20,refreshAfterWrite=1m,recordStats
        brandCache: initialCapacity=64,maximumSize=5000,refreshAfterWrite=24h,recordStats
        timeCache: initialCapacity=64,maximumSize=5000,refreshAfterWrite=30d,recordStats
        homeGoodsGroupPageCache: initialCapacity=64,maximumSize=10000,refreshAfterWrite=30d,recordStats
        homeGoodsGroupCache: initialCapacity=64,maximumSize=10000,refreshAfterWrite=30d,recordStats
        purchaseWouldCache: initialCapacity=64,maximumSize=10000,refreshAfterWrite=30d,recordStats
        goodsPriceRevisionListCache: initialCapacity=64,maximumSize=10000,refreshAfterWrite=30d,recordStats
        actDiscountCache: initialCapacity=64,maximumSize=10000,refreshAfterWrite=30d,recordStats
        brandParentFirstPushCache: initialCapacity=64,maximumSize=10000,refreshAfterWrite=60m,recordStats
    # 二级缓存
    redis:
      # 加载数据时，是否加锁
      lock: false
      # 加锁时，true调用tryLock()，false调用lock()
      tryLock: true
      # 批量操作的大小，可以理解为是分页
      batchPageSize: 3
      # 缓存过期时间(ms)
      #expireTime: 30000
      # 缓存最大空闲时间(ms)
      #maxIdleTime: 30000
      # 最大缓存数
      #maxSize: 200
      # Redisson 的yaml配置文件
      redissonYamlConfig: redisson.yaml
    # 缓存同步策略配置
    cacheSyncPolicy:
      # 策略类型 kafka / redis
      type: redis
      # 缓存更新时通知其他节点的topic名称
      topic: l2cache
      # 具体的属性配置，不同的类型配置各自的属性即可(自定义和原生的都可以)
      #props:
      #  # kafka properties config
      #  bootstrap.servers: localhost:9092
      #  # 生产者id
      #  client.id: L2CacheProducer
      #  # 发送消息的确认机制
      #  acks: 1
      #  # key序列化处理器
      #  key.serializer: org.apache.kafka.common.serialization.StringSerializer
      #  # value序列化处理器
      #  value.serializer: org.apache.kafka.common.serialization.StringSerializer
      #  # 消费者groupid
      #  # 因为是缓存同步，所以必须让所有消费者都消费到相同的消息。采用动态生成一个id附加到配置的group.id上，实现每个consumer都是一个group，来实现发布订阅的模式。
      #  group.id: L2CacheConsumerGroup
      #  # 自动提交offset（默认true）
      #  enable.auto.commit: true
      #  # 自动提交间隔
      #  auto.commit.interval.ms: 1000
      #  # key反序列化处理器
      #  key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #  # value反序列化处理器
      #  value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #  # 设置消费的位置
      #  auto.offset.reset: latest
      #  # 设置一次最大拉取的消息条数（默认500）
      #  max.poll.records: 10
      #  # 设置poll最大时间间隔（默认3s）
      #  max.poll.interval.ms: 3000
#    hotkey:
#      hotkeyType: jd
#      jdHotKey:
#        serviceName: weeget-bullet-goods-rest
#        #etcd的地址，如有多个用逗号分隔
#        etcdUrl: http://127.0.0.1:2379